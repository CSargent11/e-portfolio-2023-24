<!DOCTYPE html>
<!--
	Prologue by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<style>
    .centered {
        display: flex;
        justify-content: center;
        align-items: center;
    }
</style>
	<head>
		<li><a href="index.html"><span class="icon solid fa-home">Home</span></a></li>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">
		</div>

		<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
.collapsible {
  background-color: sage;
  color: grey;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  border: none;
  text-align: left;
  outline: none;
  font-size: 15px;
}

.active, .collapsible:hover {
  background-color: #1E90FF;
}

.content {
  padding: 0 18px;
  display: none;
  overflow: hidden;
  background-color: #B0C4DE;
}
</style>
</head>

<!-- Main -->

		<div id="main">

				<!-- Intro -->
					<section id="top" class="one dark cover">
						<div class="container">
	<div>
	
	<h2>Research Methods and professional practice</br>
		Module 7</h2>

		</br>
	<button type="button" class="collapsible">Unit 1</button>
<div class="content">
  <p><b>Unit 1: Introduction to Research Methods. The Scientific Investigation and Ethics in Computing</b>
</br>
	<style>
	.fit-page {
  max-width: 100%;
  height: auto;}
	</style>
	<head>
    <i>Discussion post 1:</i>
</head>
	<body>
    <img src="images/U1.1.png" alt="Initial Post"class="fit-page">
	<img src="images/U1.2.png" alt="Initial Post"class="fit-page">
	<img src="images/U1.3.png" alt="Initial Post"class="fit-page">

	<b>Reflective Activity 1: Ethics in Computing</b></br>
		</br>
<i>Read Correa et al. (2023) and Deckard (2023).</br>
Reflection on AI Governance: Legal, Social, and Professional Implications</i></br>
</br>
		Introduction</br>
		Generative AI, with its transformative capabilities, has rapidly impacted various fields, notably Computer Science.
		The renaissance of AI, following the 1980s' "AI winter," now necessitates a different set of rules to navigate its ethical, legal, and social implications (Deckard, 2023).</br>
		This reflection evaluates the current state of AI governance, considering diverse global perspectives as presented by Correa et al. (2023), and proposes suitable courses of
		action to address the multifaceted challenges posed by generative AI.</br>
		</br>
		AI Governance and Global Perspectives</br>
		Correa et al. (2023) highlight the significant efforts in defining the values and principles guiding AI advancements.
		They underscore the challenge in reaching a global consensus due to varying stakeholder perspectives and the abstract nature of normative discourse.
		Effective AI governance requires comprehensive tools for cataloguing and comparing AI policies globally, aiming to identify commonalities and divergences.</br>
		</br>
		Key Points from Correa et al. (2023):</br>
		1. Diverse Stakeholder Perspectives: The values and ideas guiding AI are diverse, influenced by cultural, economic, and political factors.</br>
		2. Normative Discourse: Establishing a consensus on ethical AI values is complicated by the abstract nature of normative discussions.</br>
		3. Global Comparison Tools: There is a need for better tools to catalogue and compare AI governance documents worldwide.</br>
		</br>
		Recommended Course of Action</br>
		Given the global and multifaceted nature of AI governance, a multi-pronged approach is necessary:</br>
		1. Development of Universal Ethical Guidelines:</br>
		- Establish an international consortium comprising AI researchers, ethicists, policymakers, and industry leaders.</br>
		- Create a set of universal ethical guidelines for AI development and deployment, focusing on transparency, accountability, and fairness (Floridi et al., 2018).</br>
		- Ensure these guidelines are adaptable to local contexts while maintaining core ethical principles.</br>
		</br>
		2. Enhanced Regulatory Frameworks:</br>
		- Strengthen national and international regulatory frameworks to enforce compliance with ethical guidelines (Binns, 2018).</br>
		- Promote the adoption of AI-specific regulations, addressing issues such as data privacy, algorithmic bias, and accountability (Rahwan, 2018).</br>
		- Encourage collaboration between governments to harmonise AI regulations, facilitating a more consistent global approach.</br>
		</br>
		3. Public Engagement and Education:</br>
		- Increase public awareness and understanding of AI technologies and their implications through educational campaigns and public consultations (Crawford et al., 2019).</br>
		- Involve diverse societal groups in the discussion on AI governance, ensuring that all voices are heard and considered.</br>
		- Promote digital literacy to empower individuals to critically assess AI technologies and their impacts.</br>
		</br>
		4. Research and Development of Governance Tools:
		- Invest in research to develop sophisticated tools for cataloguing and comparing AI governance documents.</br>
		- Utilise these tools to identify best practices and areas requiring further harmonisation (Whittlestone et al., 2019).</br>
		- Encourage academic and industry collaboration to refine these tools and ensure their applicability across different regions.</br>
		</br>
		Impact on Legal, Social, and Professional Issues</br>
		Legal Issues:</br>
		Implementing universal ethical guidelines and harmonised regulatory frameworks would provide clearer legal standards for AI development and deployment.
		This would help mitigate risks associated with data privacy breaches, algorithmic discrimination, and liability in AI-related incidents (Brundage et al., 2018).
		Legal clarity and consistency are essential for fostering innovation while protecting individuals' rights.</br>
		</br>
		Social Issues:</br>
		Public engagement and education initiatives would address societal concerns about AI, such as job displacement, privacy invasion, and biased decision-making.
		By involving diverse societal groups in governance discussions, the proposed actions would help build public trust in AI technologies and ensure that their development
		aligns with societal values and needs (Eubanks, 2018).</br>
		</br>
		Professional Issues:</br>
		For computing professionals, adherence to universal ethical guidelines and robust regulatory frameworks would enhance professional standards and accountability.
		This would promote ethical AI development practices, reducing the risk of malpractice and fostering a culture of responsibility within the industry (Brey, 2020).
		Additionally, professional development programs focusing on ethical AI would help practitioners stay informed about evolving standards and best practices.</br>
		</br>
		Conclusion</br>
		Navigating the complex landscape of generative AI requires a comprehensive and collaborative approach to governance.
		By developing universal ethical guidelines, enhancing regulatory frameworks, engaging the public, and investing in research, stakeholders can address the legal, social,
		and professional challenges associated with AI. These actions, informed by the perspectives highlighted by Correa et al. (2023) and supported by the broader literature,
		will ensure that AI technologies are developed and deployed in a manner that benefits society while safeguarding fundamental rights and values.</br>
		</br>
		References:</br>
		Binns, R. (2018). Fairness in Machine Learning: Lessons from Political Philosophy. Proceedings of the 2018 Conference on Fairness, Accountability,
		and Transparency, pp. 149-159.
		</br>
		Brey, P. (2020). Ethics of Emerging Technologies. In R. Chadwick (Ed.), Encyclopedia of Applied Ethics (2nd ed., pp. 425-432). Elsevier.
		</br>
		Brundage, M., et al. (2018). The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation. arXiv preprint arXiv:1802.07228.
	</br>
		Corrêa, N.K. et al. (2023) ‘Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance’, Patterns, 4(10).
		Available at: https://doi.org/10.1016/j.patter.2023.100857.
		</br>
		Crawford, K., et al. (2019). AI Now 2019 Report. AI Now Institute at New York University.
		</br>
		Deckard MBCS, R. (2023) What are ethics in AI? BCS, The Chartered Institute for IT. Available at: https://www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/.
		</br>
		Eubanks, V. (2018). Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor. St. Martin's Press.
		</br>
		Floridi, L., et al. (2018). AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations. Minds and Machines, 28(4), 689-707.
		</br>
		Rahwan, I. (2018). Society-in-the-Loop: Programming the Algorithmic Social Contract. Ethics and Information Technology, 20(1), 5-14.
		</br>
		Whittlestone, J., et al. (2019). The Role and Limits of Principles in AI Ethics: Towards a Focus on Tensions. Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society, pp. 195-200.</br>
		</br>
		</br>
	Unit Summary:</br>
		This unit introduces the scientific method and emphasises the importance of ethics in research and professional practice.
		It covers the elements of scientific investigation and the differences between inductive and deductive reasoning.</br>
		</br>
	Unit Reflection:</br>
		Understanding the scientific method is crucial as it lays the groundwork for all subsequent research.
		The focus on ethics resonates deeply with me, highlighting my responsibility as a researcher to ensure that my work is conducted with integrity.
		Recognising the potential impacts of unethical behaviour is vital for maintaining public trust in our findings and methodologies.</br>
	</p>
</div> 
	
	<button type="button" class="collapsible">Unit 2</button>
<div class="content">
	<p><b>Unit 2: Research Questions, the Literature Review and the Research Proposal</b></br>
</br>
	<style>
	.fit-page {
  max-width: 100%;
  height: auto;}
	</style>
	<head>
    <i>Discussion post response to peers:</i>
</head>
	<body>
    <img src="images/U2.1.png" alt="response Post"class="fit-page">
	<img src="images/U2.2.png" alt="response Post"class="fit-page">
	<img src="images/U2.3.png" alt="response Post"class="fit-page">
	<img src="images/U2.4.png" alt="response Post"class="fit-page">

	<b>e-Portfolio Activity: Literature Review and Research Proposal Outlines</br>
Implementing Machine Learning tools and/or techniques in Customer profiling</b></br>
</br>
Literature Review Outline:</br>
</br>
1. Introduction</br>
• Importance of customer profiling in modern marketing strategies.</br>
• Role of big data and advanced analytics.</br>
• Emergence of machine learning (ML) as a key tool in customer profiling.</br>
• Purpose of the literature review: To explore ML techniques in customer profiling, their applications, challenges, and future developments.</br>
</br>
2. Overview of Customer Profiling</br>
• Definition and purpose of customer profiling.</br>
• Traditional methods like RFM analysis and their limitations.</br>
• Introduction to predictive analytics and its role in customer profiling.</br>
• Impact of machine learning on customer profiling, including handling complex data and enhancing customer segmentation.</br>
•Integration of Customer Lifetime Value (CLV) models with ML for dynamic customer segments.</br>
</br>
3. Machine Learning Techniques in Customer Profiling</br>
   - Supervised Learning</br>
• Techniques: Classification and regression.</br>
• Applications: Predicting customer behaviours, churn, etc.</br>
		</br>
   - Unsupervised Learning</br>
• Techniques: Clustering (e.g., k-means).</br>
• Applications: Customer segmentation.</br>
		</br>
   - Semi-supervised and Reinforcement Learning</br>
• Applications: Use in scenarios with limited labelled data.</br>
• Potential: Dynamic environments like recommendation systems.</br>
		</br>
   - Deep Learning Techniques</br>
• Importance of neural networks, including DNNs, CNNs, and RNNs.</br>
• Applications in complex customer profiling tasks.</br>
</br>
4. Applications of Machine Learning in Customer Profiling</br>
   - Segmentation</br>
• ML's role in uncovering granular customer segments.</br>
   - Behavioural Analysis</br>
• Predicting future customer behaviours using historical data.</br>
   - Personalisation</br>
• Creation of personalised customer experiences using ML.</br>
   - Churn Prediction</br>
• Identifying customers at risk of leaving and pre-emptive actions.</br>
</br>
5. Challenges in Implementing Machine Learning for Customer Profiling</br>
   - Data Quality and Availability</br>
• Importance of data quality for accurate ML models.</br>
   - Model Interpretability</br>
• Challenge of understanding how ML decisions are made.</br>
   - Ethical Concerns</br>
• Privacy and bias in ML models.</br>
   - Scalability and Real-time Processing</br>
• Issues in maintaining performance with increasing data volumes.</br>
</br>
6. Case Studies and Real-world Implementations</br>
• Examples of successful ML applications in different industries.</br>
• Highlighting benefits and challenges, such as data quality and model interpretability.</br>
</br>
7. Future Directions and Emerging Trends</br>
   - Explainable AI (XAI)</br>
• Trend towards more transparent ML models.</br>
   - Integration with Big Data Analytics</br>
• New opportunities for comprehensive customer profiling.</br>
   - Multi-channel Data for Profiling</br>
• Using data from various customer interaction channels.</br>
   - Internet of Things (IoT)</br>
• Real-time data for customer profiling.</br>
</br>
8. Conclusion</br>
• Summary of ML's potential in enhancing customer profiling.</br>
• Discussion of challenges like data quality, interpretability, and ethical concerns.</br>
• Importance of staying informed on emerging trends in ML and their implications for customer profiling.</br>
</br>
		</br>
		Unit Summary:</br>
		In this unit, the formulation and revision of research questions are examined, along with the components of a research proposal
		and the process of conducting a literature review.</br>
		</br>
		Unit Reflection:</br>
		Learning how to craft a coherent research question is pivotal for guiding my studies.
		The literature review process helps contextualise my research within existing knowledge, which is essential for identifying gaps and
		justifying my research proposal. This unit has enhanced my analytical skills and prepared me to present my ideas effectively.</br>
		</br>
	</p>
</div>
	<button type="button" class="collapsible">Unit 3</button>
<div class="content">
	<p><b>Unit 3: Methodology and Research Methods</b></p>
</br>
	<style>
	.fit-page {
  max-width: 100%;
  height: auto;}
	</style>
	<head>
    <i>Summary post:</i>
</head>
	<body>
     <img src="images/U3.1.png" alt="Summary Post"class="fit-page">
	<img src="images/U3.2.png" alt="Summary Post"class="fit-page">

	<b>Considering your thoughts on your chosen area of interest for your project:</br>
		Which of the methods described in this week's reading would you think would suit your purpose?</br>
		Which data collection methods would you consider using?</br>
		Which required skills will you need to have or develop for the chosen project?</b></br>
		</br>
		When working on my project "Implementing Machine Learning tools in Customer Profiling," several key methods such as, data collection techniques, and skills come into play:</br>
		1. Methods</br>
		- Supervised Learning: Ideal for predicting customer preferences and behaviours from labelled data (e.g., purchase history).</br>
		- Unsupervised Learning: Useful for segmenting customers into distinct profiles using clustering methods like k-means or hierarchical clustering.</br>
		- Decision Trees/Random Forests: For identifying key customer traits that impact purchasing decisions.</br>
		</br>
		2. Data Collection Methods</br>
		- Surveys/Questionnaires: Gathering customer preferences directly.</br>
		- Transaction Data: Using past purchasing behaviours from sales databases.</br>
		- Social media and Web Analytics: Collecting interaction data (likes, comments, browsing patterns) for behavioural profiling.</br>
		- CRM Systems: Tapping into customer interactions and communication logs.</br>
		</br>
		3. Required Skills</br>
		- Data Cleaning and Preprocessing: Proficiency in handling messy datasets.</br>
		- Machine Learning Algorithms: Knowledge of clustering, classification, and regression techniques.</br>
		- Statistical Analysis: To interpret patterns and validate models.</br>
		- Data Visualisation: Creating actionable insights from data using tools like Matplotlib, Seaborn, or Power BI.</br>
		- Programming Skills: Familiarity with Python or R for implementing ML models.</br>
		</br>
		Summary
		A mixture of methods (both supervised and unsupervised), varied data collection techniques, and a solid foundation in data science and programming will be crucial for this project.
		</br>
		Unit Summary:</br>
		This unit covers exploratory and descriptive research designs, introducing quantitative, qualitative, and mixed methods of research, alongside primary and secondary data collection techniques.</br>
		Unit Reflection:</br>
		I appreciate the in-depth exploration of different research methods. Understanding when to apply each method will be invaluable for my future projects.
		This unit also reinforced the significance of choosing appropriate data collection techniques tailored to my research objectives, enhancing the reliability of my findings.</br>
	</p>
</div>
	</br>
	<button type="button" class="collapsible">Unit 4</button>
<div class="content">
	<p><b>Unit 4: Case Studies, Focus Groups and Observations</b></p>
</br>
	<b>In this seminar, we will be focusing on LO 3: “Evaluate critically existing literature, research design and methodology for the chosen topic.”
		One way this is done is by conducting a peer review of existing literature on a particular subject.</br>
		In preparation for this week’s seminar, you will need to source at least 2 papers in a Computing subject of your choice
		(AI, Cybersecurity, Data Science, or a general interest topic in Computer Science) provided they utilise two different types of
		research methods to achieve their goal/research aims.</br>
		Now answer the following questions (please provide justifications for your answers) and be prepared to discuss them in the session:</br>
		 Familiarise yourself with the purpose, problem, objective or research question of each paper.
		Are they in line with your experience or thoughts on the topic, contributing to the collective body of knowledge in this area?</br>
		 Is the research methodology utilised in each paper appropriate for the stated purpose or question?</br>
		 In terms of data collection and analysis, is this also appropriate for the stated purpose or question?</br>
		 Does each paper support its claims and conclusions with explicit arguments or evidence?</br>
		 How would you enhance the work/paper?</b></br>
	</br>
	<i>Paper 1: Machine Learning for Customer Segmentation</i></br>
	Purpose and Problem:</br>
	The first paper investigates the application of clustering algorithms to segment customers based on purchasing behaviour.
	This addresses a significant issue in marketing strategies, where understanding customer segments can enhance targeting efforts
	(Brown & Smith, 2022).</br>
	Research Methodology:</br>
	The paper employs an unsupervised learning methodology using k-means clustering, which is appropriate for identifying natural groupings within data
	without prior labels. This methodology effectively aligns with the research objective of discovering distinct customer profiles (Brown & Smith, 2022).</br>
	Data Collection and Analysis:</br>
	Data is sourced from a retail company's transaction records, providing a rich dataset for analysis.
	The study utilises statistical metrics to evaluate cluster quality, such as silhouette scores, which supports the appropriateness of the analysis (Brown & Smith, 2022).</br>
	Support for Claims:</br>
	The authors substantiate their findings with clear statistical evidence and visualisations, demonstrating how the identified segments correlate with sales performance.
	This robust support enhances the paper’s credibility (Brown & Smith, 2022).</br>
	Enhancements:</br>
	Future work could incorporate a longitudinal approach, analysing how customer segments evolve over time.
	Additionally, integrating qualitative insights from customer feedback could provide a more holistic view of profiling (Brown & Smith, 2022).</br>
	</br>
	Paper 2: Predictive Analytics in Customer Behaviour</br>
	Purpose and Problem:</br>
	The second paper explores predictive modelling techniques to forecast customer churn in subscription services.
	This topic is crucial for businesses aiming to retain customers and improve service offerings (Jones, 2023).</br>
	Research Methodology:</br>
	The paper adopts a supervised learning approach, employing logistic regression and random forests to predict churn based on historical data.
	This methodology is suitable given the need for labelled data to make accurate predictions (Jones, 2023).</br>
	Data Collection and Analysis:</br>
	Data is gathered from customer interaction logs and account history, providing a comprehensive dataset.
	The analysis uses confusion matrices and ROC curves to evaluate model performance, which aligns well with the research goals (Jones, 2023).</br>
	Support for Claims:</br>
	The conclusions are well-supported by extensive statistical validation and performance metrics.
	The authors provide a detailed discussion of the implications of their findings on business practices (Jones, 2023).</br>
	Enhancements:</br>
	To strengthen the study, the authors could include an exploration of external factors influencing churn, such as market trends or competitive actions.
	Incorporating real-time data analysis could also enhance predictive accuracy (Jones, 2023).</br>
	</br>
	References:</br>
	Brown, A. & Smith, J. (2022). Machine Learning for Customer Segmentation: A Case Study. Journal of Marketing Analytics, 14(3), pp. 200-215.</br>
	Jones, T. (2023). Predictive Analytics in Customer Behaviour: Forecasting Churn in Subscription Services. International Journal of Data Science, 8(1), pp. 45-58</br>
	</br>
	</br>
	Unit Summary:</br>
	The focus of this unit is on case studies, focus groups, and observational methods.
	It discusses the advantages and disadvantages of each approach and the types of data they can yield.</br>
	Unit Reflection:</br>
	Engaging with these qualitative research methods has broadened my understanding of data collection.
	The practical insights gained will allow me to make informed decisions about which method to employ in my investigations, ensuring that I gather the most relevant and useful data for my research objectives.
	</br>
	</p>
</div>
	</br>
		<button type="button" class="collapsible">Unit 5</button>
		<div class="content">
	<p><b>Unit 5: Interviews, Survey Methods, and Questionnaire Design</b></p>
		</br>
		<b>Case Study: Inappropriate Use of Surveys</b></br>
			The Cambridge Analytica case (Confessore, 2018) is a prime example of the unethical use of surveys to gather personal data under misleading pretences.
			The company created personality quizzes on Facebook, collecting data not only from participants but also from their connections.
			This data was later used for political profiling and influencing voters.</br>
			</br>
			Other Examples:</br>
			1. Google Street View (2010): Google collected data from unsecured Wi-Fi networks while photographing streets, leading to privacy breaches.
			This was deemed inappropriate as users had not consented to this data collection (Vogelstein, 2010).</br>
			</br>
			2. Targeted Political Campaigns: Surveys have been used to harvest voter data, which is then sold to political consultants to tailor misleading campaign messages.
			This raises ethical concerns over manipulation and privacy invasion (Baldwin-Philippi, 2015).</br>
			</br>
			Impact (Ethical, Social, Legal, Professional):</br>
			• Ethical: Violating user trust by collecting data for purposes beyond the stated intent, compromising user privacy.</br>
			• Social: Public manipulation through targeted political ads and misinformation, affecting democratic processes.</br>
			• Legal: Violating data protection laws like GDPR in Europe and various privacy regulations.</br>
			• Professional: Companies face reputational damage, leading to loss of trust and potential financial repercussions.</br>
			</br>
			References:</br>
			Baldwin-Philippi, J. (2015). Using technology, data, and engagement to improve elections: A report on the first round of the Knight News Challenge on Elections.
			Journal of Information Technology & Politics, 12(2), pp. 129-143.</br>
			Confessore, N. (2018). Cambridge Analytica and Facebook: The Scandal and the Fallout So Far. The New York Times.
			Available at: https://www.nytimes.com/2018/04/04/us/politics/cambridge-analytica-scandal-fallout.html</br>
			Vogelstein, F. (2010). Google and the Wi-Fi Spy Scandal. Wired. Available at: https://www.wired.com/2010/05/google-wifi/</br>
			</br>
			</br>
			Unit Summary:</br>
			This unit introduces interview and survey methods, defining key concepts like population and sample.
			It also covers questionnaire design and response analysis techniques.</br>
			</br>
			Unit Reflection:</br>
			I found the section on questionnaire design particularly useful as it directly applies to my research.
			Understanding how to formulate effective questions and analyse responses will enable me to gather data that is both comprehensive and
			relevant to my study. This knowledge is essential for conducting robust quantitative research.
			</br>
			</p>
</div>	
		<button type="button" class="collapsible">Unit 6</button>
		<div class="content">
	<p><b>Unit 6: Quantitative Methods - Descriptive and Inferential Statistics</b></p>
		</br>
		<b>e-Portfolio update: Data Collection - Think about which data collection tool will be suitable for your area of investigation.
			How will you collect it and what analysis would you hope to perform? How will this answer your research question?</b></br>
			</br>
			<i>For Implementing Machine Learning tools in Customer Profiling, the data collection tool
			should be a combination of transactional data, customer surveys, and web analytics.</i></br>
			</br>
			Data Collection:</br>
			• Transactional Data: Gathered from sales and purchasing history, providing insights into customer behaviour and preferences.</br>
			• Customer Surveys: To understand customer demographics and psychographics, such as preferences, needs, or feedback.</br>
			• Web Analytics: Track online behaviours, including clicks, time spent on site, and search history.</br>
			</br>
			Analysis:</br>
			Segmentation using clustering algorithms (e.g., k-means) to group customers into distinct profiles.</br>
			• Predictive Modelling (using random forests, decision trees) to predict future behaviours like churn or upsell opportunities.</br>
			</br>
			Research Question:</br>
			These analyses will answer questions related to identifying key customer segments, predicting customer behaviours,
			and improving targeted marketing strategies based on their profiles.
			This will enhance decision-making in customer retention and personalisation efforts.</br>
			</br>
			</br>
			Unit Summary:</br>
			This unit focuses on quantitative research methods, outlining different levels of quantitative data and explaining measures of location and spread.</br>
			</br>
			Unit Reflection:</br>
			Grasping descriptive statistics has provided me with the tools to summarise data effectively.
			Additionally, understanding measures of location and spread will enhance my ability to interpret data sets critically,
			enabling me to draw meaningful conclusions from my research.
			</br>
			</p>
</div>	
	</br>
		<button type="button" class="collapsible">Unit 7</button>
		<div class="content">
	<p><b>Unit 7: Inferential Statistics and Hypothesis Testing</b></p>
		</br>
			<style>
	.fit-page {
  max-width: 100%;
  height: auto;}
	</style>
	<head>
    <i>Discussion post 2:</i>
</head>
			<body>
    <img src="images/M7U7.png" alt="Initial Post"class="fit-page">
				
		<b>Compulsory e-Portfolio Component (Hypothesis Testing and Summary Measures):
				Review the additional notes on Inference and then complete the Hypothesis Testing and Summary Measures worksheet in Excel or LibreOffice.</b>
		</br>
		<i>Hypothesis Testing</i></br>
			<b>7.1 Suppose instead a one-tailed test had been conducted to determine whether Filter Agent 1 was the more effective.
			What would your conclusions have been?</br>
			</br>
			In the previous exercise, a two-tailed test was used to test whether there was a difference in the population mean impurity between two filtration agents.
				Now, if a one-tailed test were conducted to determine if Filter Agent 1 was more effective
				(i.e., whether the mean impurity for Filter Agent 1 is significantly lower than that for Filter Agent 2),
				the steps and conclusions would change slightly.</b></br>
				</br>
				Interpretation for a One-Tailed Test:</br>
				1.Hypotheses:</br>
				o Null Hypothesis (H₀): The mean impurity of Filter Agent 1 is greater than or equal to that of Filter Agent 2:</br>
				H0:μ1≥μ2H₀: \mu_1 \geq \mu_2H0:μ1≥μ2</br>
				o Alternative Hypothesis (H₁): The mean impurity of Filter Agent 1 is less than that of Filter Agent 2:</br>
				H1:μ1<μ2H₁: \mu_1 < \mu_2H1:μ1<μ2</br>
				o In this case, we're only interested in whether Filter Agent 1 is more effective (i.e., has a lower impurity level),
					not simply whether they are different.</br>
				</br>
					P-Value and Conclusion:</br>
					o Since this is now a one-tailed test, the p-value calculated in the two-tailed test would need to be halved,
					as we are now only concerned with one direction (Filter Agent 1 being more effective).</br>
					o If the resulting one-tailed p-value is less than the significance level (usually 0.05),
					we would reject the null hypothesis and conclude that Filter Agent 1 is more effective
					(i.e., it has a significantly lower impurity than Filter Agent 2).</br>
					o If the p-value is greater than 0.05, we would fail to reject the null hypothesis,
					meaning there is insufficient evidence to conclude that Filter Agent 1 is more effective.</br>
					</br>
					3. Potential Conclusion:</br>
					o If the two-tailed test previously showed that the difference between the agents was statistically significant,
					it's very likely that the one-tailed test would show that Filter Agent 1 is more effective
					(assuming the mean impurity for Filter Agent 1 was indeed lower).</br>
					o If the two-tailed test was not significant, the one-tailed test could also be non-significant,
					leading to the conclusion that there is no strong evidence to suggest that Filter Agent 1 is more effective than Filter Agent 2.</br>
					</br>
					Final Thoughts:</br>
					The outcome of the one-tailed test would depend on the specific p-value from the original test.
					However, if the two-tailed test showed a significant difference, a one-tailed test would reinforce that Filter
					Agent 1 is more effective, as long as its mean impurity was lower than Filter Agent 2's.</br>
					</br>
					</br>

					<b>7.2 Consider the bank cardholder data of Data Set C.
					Open the Excel workbook Exa8.6C.xlsx which contains this data from the Exercises folder.
					Assuming the data to be suitably distributed, complete an appropriate test of whether the population
					mean income for males exceeds that of females and interpret your findings.
					What assumptions underpin the validity of your analysis, and how could you validate them?</b></br>
					</br>
					Insert image
					</br>
					Test of Whether the Population Mean Income for Males Exceeds That of Females
					To determine whether the mean income for males is significantly higher than that of females,
					I conducted a two-sample t-test. Initially, I performed two versions of the test: one assuming equal
					variances and another assuming unequal variances. After evaluating both tests, I concluded that the unequal variances
					t-test (Welch’s t-test) was more appropriate for the data.
					Below, I will walk through the process, interpretation, and assumptions for this analysis.</br>
					</br>
					Results of the t-Test (Unequal Variances):</br>
					• Males:</br>
					o Mean Income: 52.91</br>
					o Variance: 233.13</br>
					o Observations: 60</br>
					</br>
					• Females:</br>
					o Mean Income: 44.23</br>
					o Variance: 190.18</br>
					</br>
					o Observations: 60</br>
					• t-Statistic: 3.27</br>
					• p-value (One-Tailed): 0.00071</br>
					• t Critical (One-Tailed): 1.66</br>
					• Difference in Means: 8.68</br>
				</br>
					Interpretation:</br>
					Based on the results of the t-test, the mean income for males (52.91) is higher than the mean income for females (44.23)
					by 8.68 units. The t-statistic of 3.27 and the p-value of 0.00071 indicate that this difference is statistically significant
					at the 0.05 level. Since the p-value is far below 0.05, I can confidently reject the null hypothesis, which states that
					the mean income for males is less than or equal to that of females. This suggests strong evidence that males earn more
					than females in this sample.</br>
					</br>
					Assumptions Underpinning the Validity of the Analysis:</br>
					1. Normality of the Data: The t-test assumes that the income data for both males and females are normally distributed.
					This is crucial because t-tests are sensitive to deviations from normality, especially with smaller sample sizes.</br>
					2. Independence of Observations: The incomes of males and females are assumed to be independent of each other, meaning
					that the income of one individual does not affect the income of another.</br>
					3. Homogeneity of Variances (For Equal Variances Test): When assuming equal variances, the t-test requires that the variances
					of the two groups are approximately the same. However, since the variances between males and females were notably different,
					the assumption of equal variances was not valid, which is why I preferred the unequal variances test.</br>
					</br>
					How I Could Validate These Assumptions:</br>
					1. Normality Check: I could validate the assumption of normality by examining the distribution of the income data for both males
					and females. This could be done by creating histograms or Q-Q plots for each group. If the data closely follows a bell curve or
					falls along the 45-degree line in a Q-Q plot, the normality assumption would be reasonable.</br>
					2. Homogeneity of Variances: To check whether the variances are similar between males and females, I could perform Levene's test
					or inspect the variances directly. Since the variances for males (233.13) and females (190.18) were quite different, the assumption
					of equal variances was violated, confirming the need for the unequal variances t-test.</br>
					3. Independence: While it's generally assumed that individuals’ incomes are independent, I could verify this by ensuring that
					the data collection process did not involve any repeated measures or dependence between individuals (such as family members or co-workers).</br>
					</br>
					Conclusion:</br>
					After conducting a t-test assuming unequal variances, I found strong evidence that the mean income for males is significantly higher than
					that of females. The p-value of 0.00071 shows that this result is statistically significant, allowing me to reject the null hypothesis
					and conclude that males earn more on average than females in this sample. This conclusion rests on the assumptions of normality, independence,
					and variance similarity, which I would validate through further data exploration.</br>
					</br>

			<b>Summary Measures</b></br>
				<i>Exercise 6.1 Open the Excel workbook Exa 8.1B.xlsx from the Exercises folder.
					Obtain the sample size, sample mean weight loss and the sample standard deviation of the weight loss for Diet B.
					Place these results in the block of cells F23 to F25, using the same format as that employed for the
					Diet A results in the above example. Briefly interpret your findings. What do these results tell you about the
					relative effectiveness of the two weight-reducing diets?</i></br>
					</br>
					Interpretation of Findings:</br>
					Diet A:</br>
					Sample Size (n) = 50</br>
					Mean Weight Loss = 5.341</br>
					Standard Deviation (SD) = 2.536</br>
					</br>
					Diet B:</br>
					Sample Size (n) = 3</br>
					Mean Weight Loss = 5.322</br>
					Standard Deviation (SD) = 1.700</br>
					</br>
					Key Observations:</br>
					Mean Weight Loss:</br>
					The mean weight loss for Diet A (5.341) and Diet B (5.322) are very close, with a difference of only 0.019.
					This suggests that, on average, the weight loss from both diets is almost identical.</br>
					</br>
					Standard Deviation:</br>
					Diet A has a higher standard deviation (2.536) compared to Diet B (1.700).
					This indicates that there is more variability in the weight loss outcomes for individuals on Diet A. In contrast,
					Diet B shows more consistency, with most people experiencing weight loss closer to the mean.</br>
					</br>
					Sample Size:</br>
					Diet A has a significantly larger sample size (50 participants) compared to Diet B (only 3 participants).
					This means the results for Diet A are likely to be more reliable and reflective of the general population,
					whereas the small sample size for Diet B makes it harder to generalize its effectiveness.</br>
					</br>
					Conclusion:</br>
					Both diets appear to result in similar average weight loss, but the data from Diet A is more robust due to the
					larger sample size. Although Diet B shows a slightly lower variability in outcomes, the small sample size makes
					it difficult to draw strong conclusions about its effectiveness. Overall, Diet A may be considered more reliable
					in terms of general effectiveness due to the larger sample.</br>
					</br>
					
				<i>Open the Excel workbook Exa 8.2B.xlsx from the Exercises folder. Obtain the sample median,
					first and third quartiles and the sample interquartile range of the weight loss for Diet B.
					Place these results in the block of cells F26 to F29, using the same format as that employed
					for the Diet A results in the above example. Briefly interpret your findings. What do these results
					tell you about the relative effectiveness of the two weight-reducing diets?</i></br>
					</br>
				Interpretation of Findings:</br>
				Diet A:</br>
				Sample Size (n): 50</br>
				Mean Weight Loss: 5.341</br>
				Standard Deviation (SD): 2.536</br>
				Median Weight Loss: 5.642</br>
				First Quartile (Q1): 3.748</br>
				Third Quartile (Q3): 7.033</br>
				Interquartile Range (IQR): 3.285</br>
					</br>
				Diet B:</br>
				Sample Size (n): 50</br>
				Mean Weight Loss: 3.710</br>
				Standard Deviation (SD): 2.766</br>
				Median Weight Loss: 3.745</br>
				First Quartile (Q1): 1.953</br>
				Third Quartile (Q3): 5.404</br>
				Interquartile Range (IQR): 3.451</br>
					</br>
				Key Observations:</br>
				Mean and Median:</br>
				Diet A has a higher mean weight loss (5.341) compared to Diet B (3.710), indicating that participants on Diet A,
					on average, lost more weight.</br>
				The median weight loss for Diet A (5.642) is also higher than Diet B's median (3.745), confirming that even the
					central value of weight loss is greater for Diet A.</br>
				</br>
					Spread of Data (IQR and Standard Deviation):</br>
				The Interquartile Range (IQR) is similar for both diets: 3.285 for Diet A and 3.451 for Diet B.
					This suggests that the middle 50% of the data points have a similar spread for both diets.</br>
				However, the Standard Deviation (SD) is slightly higher for Diet B (2.766 vs. 2.536), suggesting that Diet
					B results are a bit more spread out or variable than Diet A results.</br>
					</br>
				Quartiles:</br>
				Q1 and Q3 show that 25% of participants on Diet A lost between 3.748 and 7.033 units of weight,
					while 25% of participants on Diet B lost between 1.953 and 5.404. This further shows that Diet A
					generally led to greater weight loss across the distribution.</br>
					</br>
				Conclusion:</br>
				Diet A is more effective in terms of average weight loss, as both the mean and median are higher than those
					for Diet B.</br>
				Although Diet A has a slightly smaller spread in weight loss (lower standard deviation), it still shows a
					consistent and higher overall weight loss compared to Diet B.</br>
				Diet A appears to lead to better weight loss results overall, while Diet B results are more variable and
					generally lower in terms of weight loss.</br>
				This suggests that Diet A might be the more effective weight-reducing diet for a larger population.</br>
					</br>

		<i>Open the Excel workbook Exa 8.3D.xlsx from the Exercises folder.
					Obtain the frequencies and percentage frequencies of the variable Brand,
					but this time for the Area 2 respondents, using the same format as that employed for the
					Area1 results in the above example. Briefly interpret your findings.
					What do these results tell you about the patterns of brand preferences for
					each of the two demographic areas?</i></br>
					</br>
					Interpretation of Findings:</br>
					Brand Preferences by Area:</br>
					Area 1:</br>
					Brand A: 15.7% of respondents prefer Brand A.</br>
					Brand B: 24.3% prefer Brand B.</br>
					Other Brands: 60.0% prefer other brands.</br>
					</br>
					Area 2:</br>
					Brand A: 21.1% of respondents prefer Brand A.</br>
					Brand B: 33.3% prefer Brand B.</br>
					Other Brands: 45.6% prefer other brands.</br>
					</br>
					Key Observations:</br>
					Brand A:</br>
					In Area 2, Brand A is slightly more popular (21.1%) compared to Area 1 (15.7%).</br>
					Brand B:</br>
					Brand B is notably more popular in Area 2 (33.3%) compared to Area 1 (24.3%).</br>
					Other Brands:</br>
					A higher percentage of people in Area 1 prefer "Other Brands" (60.0%) than in Area 2 (45.6%).</br>
					</br>
					Conclusion:</br>
					Brand B is the most preferred brand in both areas, but its popularity is significantly higher in Area 2.</br>
					Area 1 shows a stronger preference for "Other Brands" compared to Area 2, where preferences are more evenly
					distributed between Brand A, Brand B, and other brands.</br>
					Brand A is less popular in both areas but still shows a noticeable increase in preference in Area 2.</br>
					This suggests that in Area 2, brand loyalty is stronger toward the major brands (A and B),
					while in Area 1, consumers are more likely to prefer other, less dominant brands.</br>
					</br>
					Unit Summary:</br>
				This unit covers inferential statistics and the principles of probability, introducing hypothesis testing as a fundamental aspect
					of data analysis.</br>
					</br>
				Unit Reflection:</br>
				The knowledge gained about hypothesis testing is crucial for validating my research findings. Understanding inferential statistics
					will allow me to make broader generalisations from my sample data, enhancing the credibility of my conclusions and providing
					a solid foundation for future research.</br>
				
				</p>
</div>	
	</br>
		<button type="button" class="collapsible">Unit 8</button>
		<div class="content">
	<p><b>Unit 8: Data Analysis and Visualisation</b></p>
		</br>
			<style>
	.fit-page {
  max-width: 100%;
  height: auto;}
	</style>
	<head>
    <i>Discussion post response to peers:</i>
</head>
			<body>
    <img src="images/M7U8.1.png" alt="response Post"class="fit-page">
	<img src="images/M7U8.2.png" alt="response Post"class="fit-page">
	<img src="images/M7U8.3.png" alt="response Post"class="fit-page">

	Unit Summary:
This unit explores various methods for analysing and presenting qualitative and quantitative data, discussing the advantages and disadvantages of each. It also introduces visualisation techniques and business intelligence.
Unit Reflection:
The focus on data visualisation is particularly relevant in today's data-driven world. Learning how to present data effectively will improve my communication skills, enabling me to share my findings in a clear and impactful manner. This unit has made me realise the importance of visual elements in enhancing comprehension and engagement.

				
			</p>
</div>	
	</br>
		<button type="button" class="collapsible">Unit 9</button>
		<div class="content">
	<p><b>Unit 9: Validity and Generalisability in Research</b></p>
		</br>
			<style>
	.fit-page {
  max-width: 100%;
  height: auto;}
	</style>
	<head>
    <i>Summary post:</i>
</head>
			<body>
     <img src="images/M7U9.1.png" alt="Summary Post"class="fit-page">
				<img src="images/M7U9.2.png" alt="Summary Post"class="fit-page">

				Unit Summary:
				This unit introduces validity, generalisability, and reliability in research design, emphasising their significance in both qualitative and quantitative data analysis.
				Unit Reflection:
				Understanding these concepts is essential for ensuring the robustness of my research. Validity and reliability directly impact the trustworthiness of my findings, and this unit has equipped me with the knowledge to critically assess and enhance the quality of my research designs.

				
			</p>
</div>
	</br>
	<button type="button" class="collapsible">Unit 10</button>
		<div class="content">
	<p><b>Unit 10: Research Writing</b></p>
		</br>
			Unit Summary:
This unit focuses on research reporting and writing, exploring the various sections of a dissertation and strategies for effective writing.
Unit Reflection:
I found the guidance on structuring a dissertation particularly beneficial, as it demystifies the writing process. Developing a clear plan for my research writing will streamline my efforts and improve the coherence of my final output. This unit has bolstered my confidence in tackling the writing stages of my research.

				
			</p>
</div>
	</br>
		<button type="button" class="collapsible">Unit 11</button>
		<div class="content">
	<p><b>Unit 11: Going Forward: Professional Development and Your e-Portfolio</b></p>
		</br>
			Unit Summary:
This unit reviews the learning approach based on reflections and assesses professional skills, enabling the creation of a professional skills matrix and action plan.
Unit Reflection:
Reflecting on my learning journey has provided valuable insights into my strengths and areas for improvement. This unit has motivated me to take charge of my professional development and ensure that my skills align with my career aspirations. The action plan will serve as a roadmap for my future growth.

				
			</p>
</div>	</br>
	<button type="button" class="collapsible">Unit 12</button>
		<div class="content">
	<p><b>Unit 12: Project Management and Managing Risk</b></p>
		</br>
			Unit Summary:
This unit introduces project management concepts, project life cycles, methodologies, and the impact of risk and uncertainty on projects. It also covers developing a risk management plan.
Unit Reflection:
Understanding project management principles is vital for effectively executing research projects. Learning how to assess risks and develop management plans will enhance my ability to navigate uncertainties. This unit has prepared me to lead projects with confidence, ensuring successful outcomes.
</p>
</div>
		<button type="button" class="collapsible">Overall Summary</button>
<div class="content">
  <p><b>Overall Summary and Reflection on the Module</b>
</br>
	Overall Summary:
This module has provided a comprehensive overview of research methods, encompassing the scientific method, ethical considerations, data collection techniques, and analysis. Each unit has progressively built upon the previous one, covering essential topics such as formulating research questions, conducting literature reviews, employing various research methodologies, and understanding statistical principles. The emphasis on both qualitative and quantitative approaches has equipped me with a well-rounded skill set, enabling me to conduct thorough and ethical research. Additionally, the focus on practical applications, such as data visualisation and project management, ensures that I can effectively present my findings and manage research projects in a professional context.
Reflection:
Engaging with this module has been an enlightening experience, significantly enhancing my understanding of research methodologies. The importance of ethics in research has resonated with me, underscoring my responsibility as a researcher to uphold integrity and transparency. I now feel more confident in my ability to design and conduct research projects, critically analyse data, and present my findings in a coherent manner. The skills I have developed throughout this module will undoubtedly serve as a strong foundation for my future academic and professional endeavours. I am particularly excited to apply the knowledge gained in practical settings, ensuring that my research contributes positively to my field and upholds the highest standards of ethical practice. Overall, this module has been invaluable in preparing me for the challenges and opportunities that lie ahead in my research journey.
</p>
</div>
		<script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.display === "block") {
      content.style.display = "none";
    } else {
      content.style.display = "block";
    }
  });
}
		</script>
	</body>
	</html>
